
# âœ… Project: MLOps + Bioinformatics on AWS with Terraform

## ğŸ“ Directory Structure

```
bioinfra-mlops-terraform/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ outputs.tf
â”œâ”€â”€ ml_model/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ model.pkl
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ mlflow_tracking.py
â”‚   â””â”€â”€ docs/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ README.md
```

---

## ğŸ“¦ 1. Terraform Configuration (`terraform/`)

### `main.tf`

```hcl
provider "aws" {
  region = var.aws_region
}

resource "aws_instance" "mlops_instance" {
  ami           = var.ami_id
  instance_type = "t2.medium"
  key_name      = var.key_name

  user_data = <<-EOF
              #!/bin/bash
              sudo apt-get update -y
              sudo apt-get install -y python3-pip docker.io git
              pip3 install mlflow scikit-learn pandas boto3
              EOF

  tags = {
    Name = "MLOpsBioinfraInstance"
  }
}
```

### `variables.tf`

```hcl
variable "aws_region" {
  default = "us-west-2"
}

variable "ami_id" {
  default = "ami-0c55b159cbfafe1f0" # Ubuntu 20.04
}

variable "key_name" {
  default = "your-key-name"
}
```

### `outputs.tf`

```hcl
output "instance_ip" {
  value = aws_instance.mlops_instance.public_ip
}
```

---

## ğŸ¤– 2. ML Model Training (`ml_model/train.py`)

This script loads the **breast cancer dataset** from scikit-learn, trains a **RandomForestClassifier**, tracks the experiment using **MLflow**, and saves the model with `joblib`.

```python
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import mlflow
import mlflow.sklearn
import pandas as pd
import joblib

# Load dataset
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = pd.Series(data.target)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y)

# Train model
model = RandomForestClassifier(max_depth=5, random_state=42)
model.fit(X_train, y_train)

# Evaluate
acc = accuracy_score(y_test, model.predict(X_test))

# Log to MLflow
mlflow.set_experiment("BioinfraML")
with mlflow.start_run():
    mlflow.log_metric("accuracy", acc)
    mlflow.sklearn.log_model(
        sk_model=model,
        artifact_path="mlflow_model",
        input_example=X_test.iloc[0:1]
    )

# Save locally
joblib.dump(model, "model.pkl")

print(f"âœ… Accuracy: {acc}")
print("ğŸ“¦ Model saved as model.pkl and logged to MLflow.")
```

---

## ğŸ³ 3. Docker Deployment (`docker/`)

### `Dockerfile`

```Dockerfile
FROM python:3.9
WORKDIR /app
COPY ../ml_model/ .
RUN pip install -r requirements.txt
CMD ["python", "train.py"]
```

### `app.py`

A simple Flask API that loads the trained model and predicts a class given two features:

```python
from flask import Flask, request, jsonify
import joblib
import numpy as np

app = Flask(__name__)
model = joblib.load("model.pkl")

@app.route("/predict", methods=["POST"])
def predict():
    data = request.get_json()
    features = np.array([data['mean radius'], data['mean texture']]).reshape(1, -1)
    prediction = model.predict(features)[0]
    return jsonify({"prediction": int(prediction)})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

---

## ğŸ“˜ 4. Deployment Instructions

### ğŸ› ï¸ Setup

1. Install [Terraform](https://developer.hashicorp.com/terraform/install) and [AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html)
2. Configure AWS credentials:
   `aws configure`

---

### ğŸš€ Deploy Infrastructure

```bash
cd terraform
terraform init
terraform apply
```

---

### ğŸ–¥ï¸ SSH into the Instance

```bash
ssh -i your-key.pem ubuntu@<instance_ip>
```

---

### ğŸ“¦ Run ML Pipeline

```bash
cd ml_model
python3 train.py
```

---

### ğŸ³ Optionally Run Docker App

```bash
docker build -t mlapp ../docker
docker run -p 5000:5000 mlapp
```

---

## âœ… Youâ€™re Now Ready To:

* Build infrastructure with Terraform
* Train & track machine learning models
* Deploy them via Docker
* Extend it to multi-cloud (GCP, Azure), Kubernetes, GitHub Actions

---

